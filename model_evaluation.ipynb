{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Base libraries and tools imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset and Image Processing Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_dataset_files(directory):\n",
    "    \"\"\"Loads file paths and labels from the directory\"\"\"\n",
    "    class_dirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    classes = {class_name: i for i, class_name in enumerate(class_dirs)}\n",
    "\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in class_dirs:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        class_idx = classes[class_name]\n",
    "\n",
    "        files = [os.path.join(class_dir, f) for f in os.listdir(class_dir)\n",
    "                 if os.path.isfile(os.path.join(class_dir, f)) and\n",
    "                 f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        file_paths.extend(files)\n",
    "        labels.extend([class_idx] * len(files))\n",
    "\n",
    "    return file_paths, labels, classes\n",
    "\n",
    "def process_image(file_path, label):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return img, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The load_dataset_files function recursively scans through a directory structure, where each subdirectory represents a class, and builds lists of file paths and corresponding labels. The process_image function handles the transformation pipeline for individual images, including reading the file, decoding the JPEG, resizing to the target dimensions, and normalizing pixel values to the [0,1] range for model compatibility.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_test_dataset(test_dir, batch_size=BATCH_SIZE):\n",
    "    file_paths, labels, classes = load_dataset_files(test_dir)\n",
    "\n",
    "    print(f\"Classes in the test set: {classes}\")\n",
    "    print(f\"Number of test images: {len(file_paths)}\")\n",
    "\n",
    "    # Create test dataset\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    test_ds = test_ds.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_ds = test_ds.batch(batch_size, drop_remainder=True)\n",
    "    test_ds = test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Calculate the number of steps\n",
    "    test_steps = len(file_paths) // batch_size + (1 if len(file_paths) % batch_size != 0 else 0)\n",
    "\n",
    "    return test_ds, test_steps, classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_ds, test_steps, test_classes = create_test_dataset(\n",
    "    test_dir='/kaggle/input/faces-artefact-recognition/trainee_dataset/test',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model = tf.keras.models.load_model(\"best_model.keras\", compile=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model_on_test(model, test_ds, test_steps, class_names=None):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in test_ds.take(test_steps):\n",
    "        preds = model.predict(images, verbose=0)\n",
    "\n",
    "        # If the model returns probabilities\n",
    "        if preds.shape[-1] > 1:\n",
    "            pred_classes = np.argmax(preds, axis=1)\n",
    "        else:\n",
    "            pred_classes = (preds > 0.5).astype(int).flatten()\n",
    "\n",
    "        y_pred.extend(pred_classes)\n",
    "        y_true.extend(labels.numpy().astype(int))\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # ---- Metrics ----\n",
    "    print(\"\\nðŸ“Š Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    # ---- Confusion Matrix ----\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'confusion_matrix': cm,\n",
    "        'report': classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    }\n",
    "\n",
    "\n",
    "results = evaluate_model_on_test(model, test_ds, test_steps, test_classes)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_model_predictions(model, test_dataset, classes, num_images=9):\n",
    "    # Invert class dictionary to get class names by indexes\n",
    "    class_names = {v: k for k, v in classes.items()}\n",
    "\n",
    "    # Get the first batch_size of images and their labels\n",
    "    images, labels = next(iter(test_dataset))\n",
    "\n",
    "    if num_images > len(images):\n",
    "        num_images = len(images)\n",
    "\n",
    "    predictions = model.predict(images[:num_images])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Create a grid to display images\n",
    "    rows = int(np.ceil(num_images / 3))\n",
    "    cols = min(3, num_images)\n",
    "\n",
    "    plt.figure(figsize=(12, 4 * rows))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "\n",
    "        # Display image\n",
    "        img = images[i].numpy()\n",
    "        plt.imshow(img)\n",
    "\n",
    "        # Get real and predicted class labels\n",
    "        true_label = int(labels[i].numpy())\n",
    "        pred_label = predicted_classes[i]\n",
    "\n",
    "        true_class_name = class_names[true_label]\n",
    "        pred_class_name = class_names[pred_label]\n",
    "\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "\n",
    "        plt.title(f\"Real: {true_class_name}\\nPredicted: {pred_class_name}\",\n",
    "                  color=color)\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_model_predictions(model=model, test_dataset=test_ds, classes=test_classes, num_images=9)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
