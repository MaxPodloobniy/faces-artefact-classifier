# Artifact Detection in AI-Generated Face Images

This project focuses on building a binary image classification model to detect visual artifacts in AI-generated face images. The goal is to automatically filter out corrupted or distorted images that may appear in synthetic datasets used for downstream computer vision tasks.

The entire pipeline includes dataset reorganization, exploratory data analysis (EDA), extensive experimentation with different training setups, selection of the best-performing model, and a thorough evaluation process.

---

## Project Structure

The repository is organized as follows:

- **`EDA.ipynb`** — Initial analysis of the image dataset. Includes checks for duplicates, brightness distribution, file integrity, class imbalance, and visual inspection of samples.
- **`organize_dataset.py`** — Script for preprocessing and organizing the dataset. The original folder structure contained `train/` and `test/` directories with unsorted images. This script parses filenames and redistributes them into `artifacts/` and `no_artifacts/` folders based on class labels inferred from filenames.
- **`model-training-attempts/`** — A directory containing multiple experimental training notebooks and scripts. These experiments include testing different architectures, optimizers, data augmentation strategies, and oversampling methods.
- **`model_training.py`** — Final training script that implements the best model setup using a fully unfrozen VGG-19 architecture with oversampling and heavy data augmentation.
- **`model_evaluation.ipynb`** — Evaluation notebook that calculates metrics such as accuracy, precision, recall, F1-score, and confusion matrix, and visualizes model predictions.
- **`test_data/`** — A directory with test images used during training and evaluation stages.
- **`requirements.txt`** — List of required packages to run the project.
- **`README.md`** — This file.

---

## Dataset Description

The dataset consists of AI-generated face images split into two binary classes:

- **`0`** — Images **without visible artifacts**
- **`1`** — Images **with clear visual artifacts**

Images were initially placed in flat `train/` and `test/` directories. Each filename includes a binary label in its name. The `organize_dataset.py` script restructures this layout into the following structure for compatibility with PyTorch and other deep learning frameworks:

<pre lang="markdown"><code>``` 
dataset/ 
├── train/ 
│ ├── artifacts/ 
│ └── no_artifacts/ 
└── test/ 
├── artifacts/ 
└── no_artifacts/ 
```</code></pre>


---

## Training Process

Model training was preceded by multiple experiments which are stored in the `model-training-attempts/` folder. Several architectures and strategies were evaluated, including ResNet variants, EfficientNet, and VGG.

The best results were achieved using a fully unfrozen **VGG-19** network, pretrained on ImageNet. Key components of the final pipeline include:

- Oversampling of the minority class
- Strong data augmentation including random rotations, flips, brightness/contrast jittering, and affine transformations
- Use of `Adam` optimizer and `FocalLoss`
- Full fine-tuning of the backbone with no frozen layers
- Custom learning rate scheduler for smoother convergence

The final training script is implemented in `model_training.py`.

---

## Model Evaluation

The evaluation process is implemented in `model_evaluation.ipynb`. It includes:

- Computation of key classification metrics (accuracy, precision, recall, F1-score)
- Confusion matrix for binary class separation
- Visual inspection of selected true positives, true negatives, false positives, and false negatives

Evaluation was done on the held-out test set to ensure fair performance estimation.

---

## Requirements

To run this project, install dependencies from `requirements.txt`:

```bash
pip install -r requirements.txt
```
Ensure your environment supports GPU acceleration (CUDA) for faster training.

## Running the Project

Organize the dataset:  
```bash
python organize_dataset.py
```
Train the final model:  
```bash
python model_training.py
```
Run the evaluation:  
Open and run model_evaluation.ipynb in Jupyter Notebook or any compatible IDE.

## \Notes

This project operates purely on synthetic image data generated by AI models. All images are artificially created and do not represent real individuals. Artifact detection in this context refers to visual distortions introduced during image generation, such as glitches, missing facial features, or structural inconsistencies.